{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import MorphVocab\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "def lemmatization(token):\n",
    "    forms = morph_vocab(token)\n",
    "    forms_lst = []\n",
    "    for f in forms:\n",
    "        forms_lst.append(list(f)[2])\n",
    "    forms_lst = list(set(forms_lst))\n",
    "    return forms_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('telegram1.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = con.cursor()\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_for_token(qua: str):\n",
    "    x = (qua, )\n",
    "    \n",
    "    list_id_posts = []\n",
    "    for row in c.execute(\"\"\"SELECT list_posts_id FROM tokens\n",
    "                            WHERE token=?\"\"\", x):\n",
    "        list_id_posts.extend(row[-1].replace('[', '').replace(']', '').replace(' ', '').split(','))\n",
    " \n",
    "    channel_names = []\n",
    "    post_texts = []\n",
    "    for id_p in list_id_posts:\n",
    "        z = (int(id_p), )\n",
    "        for row in c.execute(\"\"\"SELECT channels.name, posts.text FROM posts JOIN channels\n",
    "            ON posts.id_channel = channels.id_channel WHERE id_post=?\"\"\", z):\n",
    "            channel_names.append(row[-2])\n",
    "            post_texts.append(row[-1])\n",
    "    return post_texts, channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_lemma(q):\n",
    "    x = (q, )\n",
    "    for row in c.execute(\"\"\"SELECT id_token, lemmas.list_tokens FROM tokens JOIN lemmas\n",
    "        ON lemmas.id_lemma = tokens.id_lemma WHERE token=?\"\"\", x):\n",
    "        tokens_id = row[-1].replace('[', '').replace(']', '').replace(' ', '').split(',')\n",
    "        i = str(row[-2])\n",
    "        tokens_id.remove(i)\n",
    "\n",
    "    list_tokens = []\n",
    "    for j in tokens_id:\n",
    "        y = (j, )\n",
    "        for row in c.execute(\"\"\"SELECT token FROM tokens\n",
    "                                WHERE id_token=?\"\"\", y):\n",
    "            list_tokens.append(row[-1])\n",
    "\n",
    "    post_texts = []\n",
    "    channel_names = []\n",
    "    for t in list_tokens:\n",
    "        a, b = get_posts_for_token(t)\n",
    "        post_texts.extend(a)\n",
    "        channel_names.extend(b)\n",
    "    return post_texts, channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_synonyms(q):\n",
    "    x = (q, )\n",
    "    for row in c.execute(\"\"\"SELECT list_synonyms FROM tokens\n",
    "        WHERE token=?\"\"\", x):\n",
    "        synonyms_id = row[-1]\n",
    "\n",
    "    list_synonyms = []\n",
    "    for j in synonyms_id:\n",
    "        y = (j, )\n",
    "        for row in c.execute(\"\"\"SELECT token FROM tokens\n",
    "                                WHERE id_token=?\"\"\", y):\n",
    "            list_synonyms.append(row[-1])\n",
    "\n",
    "    post_texts = []\n",
    "    channel_names = []\n",
    "    for s in list_synonyms:\n",
    "        a, b = get_posts_for_token(s)\n",
    "        post_texts.extend(a)\n",
    "        channel_names.extend(b)\n",
    "    return post_texts, channel_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(qua: str):\n",
    "    q = qua.lower()\n",
    "    post_texts, channel_names = get_posts_for_token(q)\n",
    "    if len(post_texts) == 0:\n",
    "        with open('posts.json', 'a', encoding='utf-8') as file:\n",
    "            json.dump('No posts yet...', file)\n",
    "    else:    \n",
    "        a, b = search_lemma(q)\n",
    "        post_texts.extend(a)\n",
    "        channel_names.extend(b)\n",
    "        c, d = search_synonyms(q)\n",
    "        post_texts.extend(c)\n",
    "        channel_names.extend(d)\n",
    "        df_output = pd.DataFrame()\n",
    "        df_output['post'] = post_texts\n",
    "        df_output['channel'] = channel_names\n",
    "        output = df_output.to_dict('records')\n",
    "        with open('posts.json', 'a', encoding='utf-8') as file:\n",
    "            json.dump(output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['сегодня делаем лол', 'сегодня делаем мем', 'сегодня делаем руссику'] ['lol', 'lol', 'russica2']\n",
      "---------\n",
      "['сегодня делаем лол', 'сегодня делаем мем', 'сегодня делаем руссику'] ['lol', 'lol', 'russica2']\n",
      "[2]\n",
      "['делаем']\n",
      "---------\n",
      "['сегодня делаем лол', 'сегодня делаем мем', 'сегодня делаем руссику', 'сегодня делаем лол', 'сегодня делаем мем', 'сегодня делаем руссику'] ['lol', 'lol', 'russica2', 'lol', 'lol', 'russica2']\n",
      "                     post   channel\n",
      "0      сегодня делаем лол       lol\n",
      "1      сегодня делаем мем       lol\n",
      "2  сегодня делаем руссику  russica2\n",
      "3      сегодня делаем лол       lol\n",
      "4      сегодня делаем мем       lol\n",
      "5  сегодня делаем руссику  russica2\n"
     ]
    }
   ],
   "source": [
    "search('делаем')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
